# Rainbow DQN Configuration

# Environment Settings
environment:
  width: 800
  height: 600
  robot_radius: 15.0
  goal_radius: 20.0
  max_speed: 5.0
  max_steps: 1000
  render_mode: null

# Agent Settings
agent:
  type: "rainbow"
  state_dim: 8
  action_dim: 4
  learning_rate: 0.00006
  gamma: 0.99
  tau: 0.005
  hidden_dims: [512, 256]
  use_noisy: true
  device: "cuda"

# Training Settings
training:
  num_episodes: 1500
  max_steps_per_episode: 1000
  batch_size: 64
  buffer_size: 100000
  learning_starts: 1000
  
  # Prioritized replay
  use_prioritized_replay: true
  alpha: 0.6  # Priority exponent
  beta_start: 0.4
  beta_frames: 100000
  
  # No epsilon needed with noisy networks
  epsilon_start: 0.0
  epsilon_end: 0.0
  epsilon_decay: 1.0
  
  # Logging
  log_interval: 10
  save_interval: 100

# Paths
paths:
  save_dir: "trained_models/rainbow"
  log_dir: "results/logs"
  figure_dir: "results/figures"
  video_dir: "results/videos"

# Experiment
experiment:
  name: "rainbow_dqn"
  seed: 42
